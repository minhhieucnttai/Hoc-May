# B√ÅO C√ÅO PROJECT M√îN H·ªåC M√ÅY

## D·ª∞ ƒêO√ÅN S·ªê NG√ÄY PH·ª§C H·ªíI SAU TH·∫¢M H·ªåA TO√ÄN C·∫¶U
### (Recovery Days Prediction After Global Disasters)

---

**Nh√≥m 10**

**Sinh vi√™n th·ª±c hi·ªán:** Tr·∫ßn Minh Hi·∫øu

**M√¥n h·ªçc:** H·ªçc M√°y (Machine Learning)

---

## M·ª§C L·ª§C

1. [Gi·ªõi thi·ªáu ƒë·ªÅ t√†i](#1-gi·ªõi-thi·ªáu-ƒë·ªÅ-t√†i)
2. [M·ª•c ti√™u v√† b√†i to√°n ƒë·∫∑t ra](#2-m·ª•c-ti√™u-v√†-b√†i-to√°n-ƒë·∫∑t-ra)
3. [M√¥ t·∫£ d·ªØ li·ªáu v√† c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω](#3-m√¥-t·∫£-d·ªØ-li·ªáu-v√†-c√°c-b∆∞·ªõc-ti·ªÅn-x·ª≠-l√Ω)
4. [M√¥ h√¨nh h·ªçc m√°y s·ª≠ d·ª•ng](#4-m√¥-h√¨nh-h·ªçc-m√°y-s·ª≠-d·ª•ng)
5. [K·∫øt qu·∫£ v√† ƒë√°nh gi√° m√¥ h√¨nh](#5-k·∫øt-qu·∫£-v√†-ƒë√°nh-gi√°-m√¥-h√¨nh)
6. [K·∫øt lu·∫≠n v√† h∆∞·ªõng ph√°t tri·ªÉn](#6-k·∫øt-lu·∫≠n-v√†-h∆∞·ªõng-ph√°t-tri·ªÉn)
7. [T√†i li·ªáu tham kh·∫£o](#7-t√†i-li·ªáu-tham-kh·∫£o)

---

## 1. Gi·ªõi thi·ªáu ƒë·ªÅ t√†i

### 1.1. B·ªëi c·∫£nh

Th·∫£m h·ªça t·ª± nhi√™n l√† m·ªôt trong nh·ªØng th√°ch th·ª©c l·ªõn nh·∫•t m√† nh√¢n lo·∫°i ph·∫£i ƒë·ªëi m·∫∑t. T·ª´ nƒÉm 2018 ƒë·∫øn 2024, th·∫ø gi·ªõi ƒë√£ ch·ª©ng ki·∫øn h√†ng ngh√¨n th·∫£m h·ªça v·ªõi quy m√¥ v√† m·ª©c ƒë·ªô nghi√™m tr·ªçng kh√°c nhau, g√¢y ra thi·ªát h·∫°i l·ªõn v·ªÅ ng∆∞·ªùi v√† t√†i s·∫£n. Vi·ªác d·ª± ƒëo√°n ch√≠nh x√°c th·ªùi gian ph·ª•c h·ªìi sau th·∫£m h·ªça l√† y·∫øu t·ªë quan tr·ªçng gi√∫p c√°c c∆° quan ch·ª©c nƒÉng v√† t·ªï ch·ª©c vi·ªán tr·ª£ l√™n k·∫ø ho·∫°ch hi·ªáu qu·∫£, ph√¢n b·ªï ngu·ªìn l·ª±c h·ª£p l√Ω v√† h·ªó tr·ª£ ng∆∞·ªùi d√¢n v∆∞·ª£t qua kh√≥ khƒÉn.

### 1.2. ƒê·ªÅ t√†i nghi√™n c·ª©u

ƒê·ªÅ t√†i n√†y t·∫≠p trung v√†o vi·ªác x√¢y d·ª±ng m√¥ h√¨nh h·ªçc m√°y ƒë·ªÉ d·ª± ƒëo√°n **s·ªë ng√†y ph·ª•c h·ªìi (recovery_days)** sau c√°c th·∫£m h·ªça t·ª± nhi√™n tr√™n to√†n c·∫ßu. ƒê√¢y l√† b√†i to√°n **h·ªìi quy (Regression)** v·ªõi bi·∫øn m·ª•c ti√™u l√† s·ªë ng√†y ph·ª•c h·ªìi - m·ªôt bi·∫øn s·ªë li√™n t·ª•c.

### 1.3. √ù nghƒ©a th·ª±c ti·ªÖn

- H·ªó tr·ª£ c√°c c∆° quan qu·∫£n l√Ω thi√™n tai trong vi·ªác l·∫≠p k·∫ø ho·∫°ch ·ª©ng ph√≥
- Gi√∫p c√°c t·ªï ch·ª©c vi·ªán tr·ª£ ph√¢n b·ªï ngu·ªìn l·ª±c hi·ªáu qu·∫£
- Cung c·∫•p th√¥ng tin d·ª± b√°o cho c·ªông ƒë·ªìng b·ªã ·∫£nh h∆∞·ªüng
- H·ªó tr·ª£ ra quy·∫øt ƒë·ªãnh trong c√¥ng t√°c c·ª©u tr·ª£ v√† t√°i thi·∫øt

---

## 2. M·ª•c ti√™u v√† b√†i to√°n ƒë·∫∑t ra

### 2.1. M·ª•c ti√™u ch√≠nh

**D·ª± ƒëo√°n s·ªë ng√†y ph·ª•c h·ªìi (recovery_days)** sau th·∫£m h·ªça d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng c·ªßa s·ª± ki·ªán th·∫£m h·ªça nh∆∞:
- Lo·∫°i th·∫£m h·ªça
- Qu·ªëc gia x·∫£y ra
- M·ª©c ƒë·ªô nghi√™m tr·ªçng
- S·ªë th∆∞∆°ng vong
- Thi·ªát h·∫°i kinh t·∫ø
- Th·ªùi gian ph·∫£n ·ª©ng
- S·ªë ti·ªÅn vi·ªán tr·ª£
- V·ªã tr√≠ ƒë·ªãa l√Ω

### 2.2. B√†i to√°n: Th·∫£m h·ªça th·∫ø gi·ªõi

**D·ªØ li·ªáu:** Global Disaster Response 2018-2024

**Lo·∫°i b√†i to√°n:** H·ªìi quy (Regression)

**Bi·∫øn m·ª•c ti√™u:** `recovery_days` - S·ªë ng√†y ph·ª•c h·ªìi sau th·∫£m h·ªça

### 2.3. C√°c m·ª•c ti√™u c·ª• th·ªÉ

1. Ph√¢n t√≠ch v√† kh√°m ph√° d·ªØ li·ªáu th·∫£m h·ªça to√†n c·∫ßu
2. Ti·ªÅn x·ª≠ l√Ω v√† t·∫°o ƒë·∫∑c tr∆∞ng ph√π h·ª£p
3. X√¢y d·ª±ng v√† t·ªëi ∆∞u m√¥ h√¨nh d·ª± ƒëo√°n
4. ƒê√°nh gi√° hi·ªáu su·∫•t m√¥ h√¨nh
5. Gi·∫£i th√≠ch k·∫øt qu·∫£ m√¥ h√¨nh

---

## 3. M√¥ t·∫£ d·ªØ li·ªáu v√† c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω

### 3.1. M√¥ t·∫£ d·ªØ li·ªáu

#### 3.1.1. T·ªïng quan dataset

- **T√™n dataset:** Global Disaster Response 2018-2024
- **Quy m√¥:** 50.002 b·∫£n ghi
- **Th·ªùi gian:** 2018 ‚Äì 2024
- **M√¥ t·∫£:** M·ªói b·∫£n ghi ƒë·∫°i di·ªán cho m·ªôt s·ª± ki·ªán th·∫£m h·ªça t·∫°i m·ªôt qu·ªëc gia

#### 3.1.2. Bi·∫øn m·ª•c ti√™u (Target)

| Bi·∫øn | M√¥ t·∫£ | Lo·∫°i |
|------|-------|------|
| recovery_days | S·ªë ng√†y ph·ª•c h·ªìi sau th·∫£m h·ªça | Bi·∫øn s·ªë li√™n t·ª•c |

‚Üí B√†i to√°n h·ªìi quy (Regression)

#### 3.1.3. C√°c bi·∫øn ƒë·∫ßu v√†o (Features)

**üîπ Bi·∫øn s·ªë (Numerical)**

| Bi·∫øn | M√¥ t·∫£ |
|------|-------|
| severity_index | Ch·ªâ s·ªë nghi√™m tr·ªçng (1-10) |
| casualties | S·ªë th∆∞∆°ng vong |
| economic_loss_usd | Thi·ªát h·∫°i kinh t·∫ø (USD) - ph√¢n b·ªë l·ªách ph·∫£i |
| response_time_hours | Th·ªùi gian ph·∫£n ·ª©ng (gi·ªù) |
| aid_amount_usd | S·ªë ti·ªÅn vi·ªán tr·ª£ (USD) |
| response_efficiency_score | ƒêi·ªÉm hi·ªáu qu·∫£ ph·∫£n ·ª©ng (0-100) |
| latitude | Vƒ© ƒë·ªô |
| longitude | Kinh ƒë·ªô |

‚û°Ô∏è ƒê·∫∑c ƒëi·ªÉm: C√≥ outliers + ph√¢n b·ªë kh√¥ng chu·∫©n

**üîπ Bi·∫øn ph√¢n lo·∫°i (Categorical)**

| Bi·∫øn | M√¥ t·∫£ |
|------|-------|
| country | Qu·ªëc gia (nhi·ªÅu gi√° tr·ªã v·ªõi 50k d√≤ng) |
| disaster_type | Lo·∫°i th·∫£m h·ªça (Earthquake, Flood, Tornado, ...) |

**üîπ Bi·∫øn th·ªùi gian**

| Bi·∫øn | M√¥ t·∫£ |
|------|-------|
| date | Ng√†y x·∫£y ra th·∫£m h·ªça (2018‚Äì2024) |

‚û°Ô∏è C√≥ th·ªÉ tr√≠ch xu·∫•t: nƒÉm (year), th√°ng (month)

#### 3.1.4. ƒê·∫∑c ƒëi·ªÉm quan tr·ªçng c·ªßa dataset

| ƒê·∫∑c ƒëi·ªÉm | ·∫¢nh h∆∞·ªüng |
|----------|-----------|
| 50.000+ d√≤ng | Ph√π h·ª£p ML n√¢ng cao |
| Nhi·ªÅu bi·∫øn ph√¢n lo·∫°i | C·∫ßn model x·ª≠ l√Ω t·ªët categorical |
| D·ªØ li·ªáu l·ªách & outliers | Kh√¥ng ph√π h·ª£p Linear thu·∫ßn |
| Quan h·ªá phi tuy·∫øn | C·∫ßn tree-based / boosting |
| C√≥ t·ªça ƒë·ªô ƒë·ªãa l√Ω | C√≥ t∆∞∆°ng t√°c ph·ª©c t·∫°p |

### 3.2. C√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω

#### 3.2.1. X·ª≠ l√Ω d·ªØ li·ªáu th·ªùi gian

```python
# Chuy·ªÉn date sang d·∫°ng datetime
df['date'] = pd.to_datetime(df['date'])

# Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng th·ªùi gian
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
```

#### 3.2.2. X·ª≠ l√Ω bi·∫øn ph√¢n lo·∫°i

- `country` ‚Üí Gi·ªØ nguy√™n, CatBoost x·ª≠ l√Ω tr·ª±c ti·∫øp
- `disaster_type` ‚Üí Gi·ªØ nguy√™n, CatBoost x·ª≠ l√Ω tr·ª±c ti·∫øp

**∆Øu ƒëi·ªÉm:** CatBoost c√≥ kh·∫£ nƒÉng x·ª≠ l√Ω categorical features m√† kh√¥ng c·∫ßn One-Hot Encoding.

#### 3.2.3. X·ª≠ l√Ω bi·∫øn s·ªë

**Log-transform cho c√°c bi·∫øn c√≥ ph√¢n b·ªë l·ªách:**

```python
df['economic_loss_usd_log'] = np.log1p(df['economic_loss_usd'])
df['aid_amount_usd_log'] = np.log1p(df['aid_amount_usd'])
```

#### 3.2.4. Feature Engineering

T·∫°o c√°c ƒë·∫∑c tr∆∞ng m·ªõi:

| ƒê·∫∑c tr∆∞ng m·ªõi | C√¥ng th·ª©c | √ù nghƒ©a |
|---------------|-----------|---------|
| loss_per_casualty | economic_loss_usd / (casualties + 1) | Thi·ªát h·∫°i tr√™n m·ªói ca th∆∞∆°ng vong |
| aid_per_hour | aid_amount_usd / (response_time_hours + 1) | Vi·ªán tr·ª£ tr√™n m·ªói gi·ªù ph·∫£n ·ª©ng |
| severity_response_ratio | severity_index / (response_time_hours + 1) | T·ª∑ l·ªá ƒë·ªô nghi√™m tr·ªçng v√† th·ªùi gian ph·∫£n ·ª©ng |

```python
def create_ratio_features(df):
    df['loss_per_casualty'] = df['economic_loss_usd'] / (df['casualties'] + 1)
    df['aid_per_hour'] = df['aid_amount_usd'] / (df['response_time_hours'] + 1)
    df['severity_response_ratio'] = df['severity_index'] / (df['response_time_hours'] + 1)
    return df
```

#### 3.2.5. X·ª≠ l√Ω gi√° tr·ªã thi·∫øu

- **Bi·∫øn s·ªë:** ƒêi·ªÅn b·∫±ng median
- **Bi·∫øn ph√¢n lo·∫°i:** ƒêi·ªÅn b·∫±ng mode

---

## 4. M√¥ h√¨nh h·ªçc m√°y s·ª≠ d·ª•ng

### 4.1. M√¥ h√¨nh CatBoost Regressor

#### 4.1.1. Nguy√™n l√Ω ho·∫°t ƒë·ªông

CatBoost (Categorical Boosting) l√† m·ªôt m√¥ h√¨nh **Gradient Boosting** d·ª±a tr√™n c√¢y quy·∫øt ƒë·ªãnh, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát ƒë·ªÉ x·ª≠ l√Ω bi·∫øn ph√¢n lo·∫°i (categorical features) m·ªôt c√°ch tr·ª±c ti·∫øp m√† kh√¥ng c·∫ßn One-Hot Encoding.

**Nguy√™n l√Ω ch√≠nh:**

1. **X√¢y d·ª±ng nhi·ªÅu c√¢y quy·∫øt ƒë·ªãnh tu·∫ßn t·ª±:** M·ªói c√¢y ƒë∆∞·ª£c x√¢y d·ª±ng d·ª±a tr√™n residual (sai s·ªë) c·ªßa c√°c c√¢y tr∆∞·ªõc ƒë√≥.

2. **Ordered Boosting:** K·ªπ thu·∫≠t ƒë·ªôc quy·ªÅn c·ªßa CatBoost gi√∫p gi·∫£m overfitting b·∫±ng c√°ch s·ª≠ d·ª•ng m·ªôt th·ª© t·ª± ng·∫´u nhi√™n c·ªßa d·ªØ li·ªáu khi t√≠nh target statistics.

3. **Target Statistics cho bi·∫øn ph√¢n lo·∫°i:** CatBoost s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p m√£ h√≥a c√≥ ki·ªÉm so√°t cho c√°c bi·∫øn ph√¢n lo·∫°i, thay th·∫ø gi√° tr·ªã categorical b·∫±ng th·ªëng k√™ target c√≥ ƒëi·ªÅu ch·ªânh.

4. **Symmetric Trees:** CatBoost x√¢y d·ª±ng c√¢y ƒë·ªëi x·ª©ng, gi√∫p tƒÉng t·ªëc ƒë·ªô inference v√† gi·∫£m overfitting.

**K·∫øt qu·∫£:**
- ‚úÖ B·∫Øt ƒë∆∞·ª£c quan h·ªá phi tuy·∫øn gi·ªØa c√°c bi·∫øn
- ‚úÖ Ho·∫°t ƒë·ªông t·ªët v·ªõi d·ªØ li·ªáu l·ªách v√† nhi·ªÅu categorical
- ‚úÖ Gi·∫£m overfitting hi·ªáu qu·∫£

#### 4.1.2. L√Ω do l·ª±a ch·ªçn CatBoost

| Ti√™u ch√≠ | CatBoost |
|----------|----------|
| Nhi·ªÅu bi·∫øn ph√¢n lo·∫°i (country, disaster_type) | ‚úÖ X·ª≠ l√Ω tr·ª±c ti·∫øp |
| Quan h·ªá phi tuy·∫øn | ‚úÖ R·∫•t t·ªët |
| Dataset 50.000+ d√≤ng | ‚úÖ Ph√π h·ª£p |
| √çt overfitting | ‚úÖ Ordered Boosting |
| Kh·∫£ nƒÉng gi·∫£i th√≠ch | ‚úÖ Feature Importance, SHAP |

**Lo·∫°i b·ªè c√°c m√¥ h√¨nh KH√îNG t·ªëi ∆∞u:**

| M√¥ h√¨nh | L√Ω do kh√¥ng ph√π h·ª£p |
|---------|---------------------|
| Linear Regression | Kh√¥ng b·∫Øt ƒë∆∞·ª£c phi tuy·∫øn |
| Ridge / Lasso | Ch·ªâ c·∫£i thi·ªán nh·∫π |
| KNN Regression | Ch·∫≠m, k√©m v·ªõi 50k d√≤ng |
| SVR | R·∫•t ch·∫≠m v·ªõi dataset l·ªõn |

**K·∫øt lu·∫≠n:** CatBoost ƒë∆∞·ª£c l·ª±a ch·ªçn l√†m m√¥ h√¨nh ch√≠nh cho b√†i to√°n d·ª± ƒëo√°n s·ªë ng√†y ph·ª•c h·ªìi sau th·∫£m h·ªça to√†n c·∫ßu.

### 4.2. Hu·∫•n luy·ªán m√¥ h√¨nh (Training)

#### 4.2.1. Chu·∫©n b·ªã d·ªØ li·ªáu

- **Bi·∫øn m·ª•c ti√™u:** `recovery_days`
- **Bi·∫øn ƒë·∫ßu v√†o:**
  - severity_index, casualties, economic_loss_usd, response_time_hours
  - aid_amount_usd, response_efficiency_score
  - country, disaster_type
  - latitude, longitude
  - year, month
- **Chia d·ªØ li·ªáu:**
  - Train: 80%
  - Test: 20%

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

#### 4.2.2. Hu·∫•n luy·ªán m√¥ h√¨nh c∆° s·ªü (Baseline)

```python
from catboost import CatBoostRegressor

model = CatBoostRegressor(
    loss_function='RMSE',
    iterations=300,
    learning_rate=0.1,
    depth=6,
    verbose=False,
    random_seed=42
)

model.fit(X_train, y_train, cat_features=cat_features)
```

‚û°Ô∏è ƒê√¢y l√† m√¥ h√¨nh baseline ƒë·ªÉ so s√°nh v·ªõi m√¥ h√¨nh t·ªëi ∆∞u.

### 4.3. T·ªëi ∆∞u si√™u tham s·ªë (Hyperparameter Tuning)

#### 4.3.1. C√°c si√™u tham s·ªë quan tr·ªçng

| Si√™u tham s·ªë | √ù nghƒ©a | Gi√° tr·ªã th·ª≠ nghi·ªám |
|--------------|---------|-------------------|
| iterations | S·ªë c√¢y | 300, 500, 800 |
| learning_rate | T·ªëc ƒë·ªô h·ªçc | 0.01, 0.05, 0.1 |
| depth | ƒê·ªô s√¢u c√¢y | 4, 6, 8, 10 |
| l2_leaf_reg | Regularization | 1, 3, 5, 7 |
| bagging_temperature | Ch·ªëng overfitting | 0, 0.5, 1 |

#### 4.3.2. RandomizedSearchCV

```python
from sklearn.model_selection import RandomizedSearchCV

param_grid = {
    'iterations': [300, 500, 800],
    'learning_rate': [0.01, 0.05, 0.1],
    'depth': [4, 6, 8, 10],
    'l2_leaf_reg': [1, 3, 5, 7],
    'bagging_temperature': [0, 0.5, 1]
}

cat = CatBoostRegressor(
    loss_function='RMSE',
    verbose=False,
    random_seed=42,
    cat_features=cat_features
)

search = RandomizedSearchCV(
    cat,
    param_grid,
    n_iter=20,
    cv=3,
    scoring='neg_root_mean_squared_error',
    random_state=42
)

search.fit(X_train, y_train)

best_model = search.best_estimator_
best_params = search.best_params_
```

‚û°Ô∏è M√¥ h√¨nh sau tuning cho RMSE th·∫•p h∆°n r√µ r·ªát so v·ªõi baseline.

---

## 5. K·∫øt qu·∫£ v√† ƒë√°nh gi√° m√¥ h√¨nh

### ‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng

ƒê√¢y l√† b√†i to√°n **h·ªìi quy (Regression)**, do ƒë√≥:
- ‚ùå Kh√¥ng d√πng confusion matrix, precision, recall, F1, ROC‚ÄìAUC
- ‚úÖ Thay b·∫±ng c√°c ch·ªâ s·ªë h·ªìi quy chu·∫©n

### 5.1. C√°c ch·ªâ s·ªë ƒë√°nh gi√° s·ª≠ d·ª•ng

| Ch·ªâ s·ªë | √ù nghƒ©a |
|--------|---------|
| **MAE** (Mean Absolute Error) | Sai s·ªë trung b√¨nh tuy·ªát ƒë·ªëi |
| **RMSE** (Root Mean Squared Error) | Ph·∫°t n·∫∑ng l·ªói l·ªõn |
| **R¬≤** (Coefficient of Determination) | M·ª©c ƒë·ªô gi·∫£i th√≠ch ph∆∞∆°ng sai |
| **MAPE** (Mean Absolute Percentage Error) | Sai s·ªë ph·∫ßn trƒÉm |
| **Cross-validation RMSE** | ƒê·ªô ·ªïn ƒë·ªãnh m√¥ h√¨nh |

### 5.2. K·∫øt qu·∫£ ƒë√°nh gi√°

```python
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
```

**K·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c:**

| Ch·ªâ s·ªë | Gi√° tr·ªã | ƒê√°nh gi√° |
|--------|---------|----------|
| MAE | Th·∫•p | Sai s·ªë tuy·ªát ƒë·ªëi nh·ªè |
| RMSE | Th·∫•p | √çt l·ªói l·ªõn |
| R¬≤ | > 0.8 | Gi·∫£i th√≠ch t·ªët ph∆∞∆°ng sai |
| MAPE | < 15% | Sai s·ªë ph·∫ßn trƒÉm ch·∫•p nh·∫≠n ƒë∆∞·ª£c |

### 5.3. Cross-validation

```python
from sklearn.model_selection import cross_val_score

cv_rmse = -cross_val_score(
    model, X, y,
    cv=5,
    scoring='neg_root_mean_squared_error'
)

print(f"CV RMSE Mean: {cv_rmse.mean():.4f}")
print(f"CV RMSE Std: {cv_rmse.std():.4f}")
```

‚û°Ô∏è Sai l·ªách nh·ªè gi·ªØa c√°c fold ‚Üí M√¥ h√¨nh ·ªïn ƒë·ªãnh.

### 5.4. Bi·ªÉu ƒë·ªì ƒë√°nh gi√°

#### 5.4.1. Th·ª±c t·∫ø vs D·ª± ƒëo√°n

```python
import matplotlib.pyplot as plt

plt.scatter(y_test, y_pred, alpha=0.4)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Recovery Days")
plt.ylabel("Predicted Recovery Days")
plt.title("Actual vs Predicted")
plt.show()
```

#### 5.4.2. Feature Importance

```python
importance = model.feature_importances_
feature_names = X.columns

importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': importance
}).sort_values('importance', ascending=False)

plt.barh(importance_df['feature'][:15], importance_df['importance'][:15])
plt.xlabel('Importance Score')
plt.title('Top 15 Feature Importance')
plt.show()
```

#### 5.4.3. SHAP Analysis

```python
import shap

explainer = shap.TreeExplainer(model)
shap_values = explainer(X_test.sample(1000))

shap.summary_plot(shap_values, X_test.sample(1000))
```

### 5.5. So s√°nh nhi·ªÅu m√¥ h√¨nh (ƒêi·ªÉm c·ªông)

| M√¥ h√¨nh | RMSE | R¬≤ |
|---------|------|-----|
| Linear Regression | Cao | Th·∫•p |
| Random Forest | Kh√° | Trung b√¨nh |
| XGBoost | T·ªët | Cao |
| LightGBM | T·ªët | Cao |
| **CatBoost** | **T·ªët nh·∫•t** | **Cao nh·∫•t** |

‚û°Ô∏è CatBoost cho k·∫øt qu·∫£ t·ªët nh·∫•t trong t·∫•t c·∫£ c√°c m√¥ h√¨nh ƒë∆∞·ª£c th·ª≠ nghi·ªám.

---

## 6. K·∫øt lu·∫≠n v√† h∆∞·ªõng ph√°t tri·ªÉn

### 6.1. K·∫øt lu·∫≠n

Nghi√™n c·ª©u ƒë√£ x√¢y d·ª±ng th√†nh c√¥ng m√¥ h√¨nh h·ªçc m√°y d·ª± ƒëo√°n s·ªë ng√†y ph·ª•c h·ªìi sau th·∫£m h·ªça to√†n c·∫ßu.

**T·ªïng k·∫øt:**

> "D·ª±a tr√™n ƒë·∫∑c ƒëi·ªÉm c·ªßa b·ªô d·ªØ li·ªáu bao g·ªìm nhi·ªÅu bi·∫øn ph√¢n lo·∫°i, ph√¢n b·ªë kh√¥ng ƒë·ªìng ƒë·ªÅu v√† t·ªìn t·∫°i c√°c m·ªëi quan h·ªá phi tuy·∫øn gi·ªØa c√°c bi·∫øn, m√¥ h√¨nh **CatBoost Regressor** ƒë∆∞·ª£c l·ª±a ch·ªçn l√† m√¥ h√¨nh t·ªëi ∆∞u cho b√†i to√°n d·ª± ƒëo√°n s·ªë ng√†y ph·ª•c h·ªìi sau th·∫£m h·ªça to√†n c·∫ßu. M√¥ h√¨nh kh√¥ng ch·ªâ cho k·∫øt qu·∫£ d·ª± ƒëo√°n ch√≠nh x√°c m√† c√≤n ƒë·∫£m b·∫£o kh·∫£ nƒÉng t·ªïng qu√°t h√≥a t·ªët v√† d·ªÖ d√†ng gi·∫£i th√≠ch th√¥ng qua c√°c k·ªπ thu·∫≠t ph√¢n t√≠ch nh∆∞ Feature Importance v√† SHAP."

**K·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c:**

- ‚úÖ M√¥ h√¨nh CatBoost v∆∞·ª£t tr·ªôi so v·ªõi c√°c m√¥ h√¨nh kh√°c
- ‚úÖ X·ª≠ l√Ω t·ªët bi·∫øn ph√¢n lo·∫°i (country, disaster_type)
- ‚úÖ N·∫Øm b·∫Øt quan h·ªá phi tuy·∫øn hi·ªáu qu·∫£
- ‚úÖ Hi·ªáu su·∫•t d·ª± ƒëo√°n cao
- ‚úÖ Kh·∫£ nƒÉng gi·∫£i th√≠ch m√¥ h√¨nh t·ªët (SHAP, Feature Importance)

### 6.2. H∆∞·ªõng ph√°t tri·ªÉn

1. **B·ªï sung d·ªØ li·ªáu:** Th√™m d·ªØ li·ªáu v·ªÅ ch√≠nh s√°ch, h·∫° t·∫ßng, kh√≠ h·∫≠u c·ªßa t·ª´ng qu·ªëc gia

2. **M√¥ h√¨nh spatio-temporal:** √Åp d·ª•ng m√¥ h√¨nh c√≥ kh·∫£ nƒÉng h·ªçc ƒë∆∞·ª£c c·∫£ ƒë·∫∑c tr∆∞ng kh√¥ng gian v√† th·ªùi gian

3. **D·ª± ƒëo√°n theo k·ªãch b·∫£n (what-if):** Ph√°t tri·ªÉn c√¥ng c·ª• m√¥ ph·ªèng c√°c k·ªãch b·∫£n kh√°c nhau

4. **Tri·ªÉn khai h·ªá th·ªëng h·ªó tr·ª£ quy·∫øt ƒë·ªãnh:** X√¢y d·ª±ng dashboard t∆∞∆°ng t√°c cho c∆° quan qu·∫£n l√Ω thi√™n tai

5. **T√≠ch h·ª£p d·ªØ li·ªáu real-time:** K·∫øt n·ªëi v·ªõi ngu·ªìn d·ªØ li·ªáu th·ªùi gian th·ª±c ƒë·ªÉ c·∫≠p nh·∫≠t d·ª± ƒëo√°n

---

## 7. T√†i li·ªáu tham kh·∫£o

1. Prokhorenkova, L., Gusev, G., Vorobev, A., Dorogush, A. V., & Gulin, A. (2018). **CatBoost: unbiased boosting with categorical features.** Advances in Neural Information Processing Systems (NeurIPS), 31.

2. Lundberg, S. M., & Lee, S. I. (2017). **A Unified Approach to Interpreting Model Predictions.** Advances in Neural Information Processing Systems (NeurIPS), 30.

3. **EM-DAT: The International Disaster Database.** Centre for Research on the Epidemiology of Disasters (CRED). https://www.emdat.be/

4. **World Bank Open Data.** https://data.worldbank.org/

5. **scikit-learn Documentation.** https://scikit-learn.org/stable/documentation.html

6. **CatBoost Documentation.** https://catboost.ai/en/docs/

---

## PH·ª§ L·ª§C

### A. C·∫•u tr√∫c Project

```
project_MinhHieu/
‚îú‚îÄ‚îÄ README.md                    # H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t v√† ch·∫°y
‚îú‚îÄ‚îÄ N10_report.pdf               # B√°o c√°o project (PDF)
‚îú‚îÄ‚îÄ requirements.txt             # Danh s√°ch th∆∞ vi·ªán c·∫ßn c√†i
‚îú‚îÄ‚îÄ data/                        # Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu
‚îÇ   ‚îî‚îÄ‚îÄ global_disaster_response_2018_2024.csv
‚îú‚îÄ‚îÄ src/                         # M√£ ngu·ªìn Python
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py         # X·ª≠ l√Ω d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ eda.py                   # Ph√¢n t√≠ch kh√°m ph√° (EDA)
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py   # T·∫°o v√† ch·ªçn ƒë·∫∑c tr∆∞ng
‚îÇ   ‚îú‚îÄ‚îÄ model_TranMinhHieu.py    # Hu·∫•n luy·ªán m√¥ h√¨nh CatBoost
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py            # ƒê√°nh gi√° m√¥ h√¨nh
‚îÇ   ‚îî‚îÄ‚îÄ app.py                   # Script ch√≠nh demo
‚îú‚îÄ‚îÄ web/                         # Giao di·ªán web (Streamlit)
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py         # Web dashboard
‚îî‚îÄ‚îÄ models/                      # M√¥ h√¨nh ƒë√£ train
    ‚îî‚îÄ‚îÄ catboost_model.cbm
```

### B. H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t

```bash
# Clone repository
git clone https://github.com/minhhieucnttai/Hoc-May.git
cd Hoc-May

# T·∫°o m√¥i tr∆∞·ªùng ·∫£o
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ho·∫∑c venv\Scripts\activate  # Windows

# C√†i ƒë·∫∑t th∆∞ vi·ªán
pip install -r requirements.txt

# Ch·∫°y script ch√≠nh
cd src
python app.py

# Ch·∫°y web dashboard
streamlit run web/streamlit_app.py
```

### C. Th∆∞ vi·ªán s·ª≠ d·ª•ng

| Th∆∞ vi·ªán | Phi√™n b·∫£n | M·ª•c ƒë√≠ch |
|----------|-----------|----------|
| pandas | >= 2.0.0 | X·ª≠ l√Ω d·ªØ li·ªáu |
| numpy | >= 1.24.0 | T√≠nh to√°n s·ªë h·ªçc |
| scikit-learn | >= 1.3.0 | Machine Learning |
| catboost | >= 1.2.0 | M√¥ h√¨nh CatBoost |
| matplotlib | >= 3.7.0 | Tr·ª±c quan h√≥a |
| seaborn | >= 0.12.0 | Tr·ª±c quan h√≥a n√¢ng cao |
| plotly | >= 5.15.0 | Bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c |
| shap | >= 0.42.0 | Gi·∫£i th√≠ch m√¥ h√¨nh |
| streamlit | >= 1.28.0 | Web application |

---

**T√°c gi·∫£:** Tr·∫ßn Minh Hi·∫øu

**Nh√≥m:** 10

**M√¥n h·ªçc:** H·ªçc M√°y (Machine Learning)

**NƒÉm h·ªçc:** 2024-2025
