# -*- coding: utf-8 -*-
"""
ƒê·ªì √°n ML - D·ª± ƒëo√°n th·∫£m h·ªça
Tr·∫ßn Minh Hi·∫øu - 2024
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import pickle
import json
import warnings
from pathlib import Path
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

warnings.filterwarnings('ignore')

st.set_page_config(page_title="D·ª± ƒëo√°n H·ªìi ph·ª•c - ML", page_icon="üåç", layout="wide")

st.markdown("""
<style>
    .header {font-size: 2.2rem; color: #1f77b4; font-weight: bold; text-align: center; margin: 20px 0;}
    .subheader {font-size: 1rem; color: #666; text-align: center;}
    .metric-box {background: #f0f8ff; padding: 15px; border-radius: 5px; border-left: 4px solid #1f77b4; margin: 10px 0;}
    .success {background: #d4edda; padding: 10px; border-radius: 5px; border-left: 4px solid #28a745; margin: 10px 0;}
    .error {background: #f8d7da; padding: 10px; border-radius: 5px; border-left: 4px solid #dc3545;}
</style>
""", unsafe_allow_html=True)

# ============ L·∫§Y D·ªÆ LI·ªÜU ============
@st.cache_data
def load_data():
    paths = [
        Path(__file__).parent / 'data' / 'global_disaster_response_2018_2024.csv',
        Path(__file__).parent.parent / 'data' / 'global_disaster_response_2018_2024.csv'
    ]
    for p in paths:
        if p.exists():
            df = pd.read_csv(p)
            # Extract year, month from date if available
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], errors='coerce')
                df['year'] = df['date'].dt.year
                df['month'] = df['date'].dt.month
                df['day'] = df['date'].dt.day
            return df
    st.error("‚ùå Kh√¥ng t√¨m th·∫•y data!")
    return None

# ============ LOAD MODELS ============
@st.cache_resource
def load_xgb():
    try:
        mp = Path(__file__).parent / 'xgboost_model.pkl'
        sp = Path(__file__).parent / 'xgboost_scaler.pkl'
        ep = Path(__file__).parent / 'xgboost_encoders.pkl'
        cp = Path(__file__).parent / 'xgboost_config.json'
        
        if mp.exists() and sp.exists() and ep.exists():
            m = pickle.load(open(mp, 'rb'))
            s = pickle.load(open(sp, 'rb'))
            e = pickle.load(open(ep, 'rb'))
            c = json.load(open(cp)) if cp.exists() else {}
            return m, s, e, c
    except Exception as ex:
        st.warning(f"‚ö†Ô∏è L·ªói XGBoost: {ex}")
    return None, None, None, None

@st.cache_resource
def load_lgb():
    try:
        mp = Path(__file__).parent / 'lightgbm_model.pkl'
        sp = Path(__file__).parent / 'lightgbm_scaler.pkl'
        ep = Path(__file__).parent / 'lightgbm_encoders.pkl'
        cp = Path(__file__).parent / 'lightgbm_config.json'
        
        if mp.exists() and sp.exists() and ep.exists():
            m = pickle.load(open(mp, 'rb'))
            s = pickle.load(open(sp, 'rb'))
            e = pickle.load(open(ep, 'rb'))
            c = json.load(open(cp)) if cp.exists() else {}
            return m, s, e, c
    except Exception as ex:
        st.warning(f"‚ö†Ô∏è L·ªói LightGBM: {ex}")
    return None, None, None, None

# ============ D·ª∞ ƒêO√ÅN ============
def predict_xgb(country, disaster, inp_data):
    xgb_m, xgb_s, xgb_e, xgb_c = st.session_state.xgb
    if not xgb_m:
        return None
    
    d = inp_data.copy()
    d['country_encoded'] = xgb_e['country'].transform([country])[0]
    d['disaster_type_encoded'] = xgb_e['disaster_type'].transform([disaster])[0]
    d.pop('country', None)
    d.pop('disaster_type', None)
    
    feats = xgb_c.get('features', [])
    X = pd.DataFrame([[d.get(f, 0) for f in feats]], columns=feats)
    X_scaled = xgb_s.transform(X)
    return xgb_m.predict(X_scaled)[0]

def predict_lgb(country, disaster, inp_data):
    lgb_m, lgb_s, lgb_e, lgb_c = st.session_state.lgb
    if not lgb_m:
        return None
    
    d = inp_data.copy()
    d['country_encoded'] = lgb_e['country'].transform([country])[0]
    d['disaster_type_encoded'] = lgb_e['disaster_type'].transform([disaster])[0]
    d.pop('country', None)
    d.pop('disaster_type', None)
    
    feats = lgb_c.get('features', [])
    X = pd.DataFrame([[d.get(f, 0) for f in feats]], columns=feats)
    X_scaled = lgb_s.transform(X)
    return lgb_m.predict(X_scaled)[0]

# ============ TRANG T·ªîNG QUAN ============
def page_overview(df):
    st.markdown('<div class="header">üìä T·ªïng Quan D·ª± √Ån</div>', unsafe_allow_html=True)
    
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("üìä Records", f"{len(df):,}")
    c2.metric("üåç Qu·ªëc gia", df['country'].nunique())
    c3.metric("‚ö° Th·∫£m h·ªça", df['disaster_type'].nunique())
    c4.metric("üìÖ NƒÉm", f"{int(df['year'].min())}-{int(df['year'].max())}")
    
    st.divider()
    
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("Recovery Days")
        st.dataframe(df['recovery_days'].describe().round(2), use_container_width=True)
    
    with c2:
        st.subheader("S·ªë li·ªáu")
        st.dataframe(df.select_dtypes(include='number').describe().T.round(2), use_container_width=True)

# ============ TRANG KH√ÅM PH√Å ============
def page_explore(df):
    st.markdown('<div class="header">üîç Kh√°m Ph√° D·ªØ Li·ªáu</div>', unsafe_allow_html=True)
    
    c1, c2 = st.columns(2)
    with c1:
        countries = st.multiselect("Qu·ªëc gia:", sorted(df['country'].unique()), 
                                   default=sorted(df['country'].unique())[:5])
        disasters = st.multiselect("Th·∫£m h·ªça:", sorted(df['disaster_type'].unique()),
                                  default=sorted(df['disaster_type'].unique())[:3])
        min_r = st.slider("Min Recovery:", int(df['recovery_days'].min()), int(df['recovery_days'].max()), 
                         int(df['recovery_days'].min()))
        max_r = st.slider("Max Recovery:", int(df['recovery_days'].min()), int(df['recovery_days'].max()), 
                         int(df['recovery_days'].max()))
    
    filt = df[(df['country'].isin(countries)) & 
              (df['disaster_type'].isin(disasters)) &
              (df['recovery_days'] >= min_r) &
              (df['recovery_days'] <= max_r)]
    
    with c2:
        st.metric("üìå B·∫£n ghi", len(filt))
        st.metric("üìà Thay ƒë·ªïi", f"{len(filt) - len(df):,}")
    
    st.dataframe(filt.head(20), use_container_width=True, hide_index=True)

# ============ TRANG BI·ªÇU ƒê·ªí ============
def page_viz(df):
    st.markdown('<div class="header">üìà Bi·ªÉu ƒê·ªì & Th·ªëng K√™</div>', unsafe_allow_html=True)
    
    c1, c2 = st.columns(2)
    
    with c1:
        fig = px.histogram(df, x='recovery_days', nbins=40, 
                          title='Ph√¢n ph·ªëi Recovery Days', 
                          color_discrete_sequence=['#1f77b4'])
        st.plotly_chart(fig, use_container_width=True)
    
    with c2:
        fig = px.box(df, y='recovery_days', title='Box Plot Recovery',
                    color_discrete_sequence=['#ff7f0e'])
        st.plotly_chart(fig, use_container_width=True)
    
    st.divider()
    
    c1, c2 = st.columns(2)
    
    with c1:
        top_countries = df.groupby('country')['recovery_days'].mean().sort_values(ascending=False).head(10)
        fig = px.bar(top_countries, title='Top 10 Qu·ªëc Gia', color_discrete_sequence=['#2ca02c'])
        st.plotly_chart(fig, use_container_width=True)
    
    with c2:
        by_disaster = df.groupby('disaster_type')['recovery_days'].mean().sort_values(ascending=False)
        fig = px.bar(by_disaster, title='Theo Lo·∫°i Th·∫£m H·ªça', color_discrete_sequence=['#d62728'])
        st.plotly_chart(fig, use_container_width=True)

# ============ TRANG TH√îNG TIN MODEL ============
def page_model_info():
    st.markdown('<div class="header">ü§ñ Th√¥ng Tin Models</div>', unsafe_allow_html=True)
    
    st.markdown("""
    ### XGBoost & LightGBM
    
    **XGBoost Regressor**
    - R¬≤ = 93.64% | MAE = 4.05 ng√†y | RMSE = 5.08 ng√†y
    
    **LightGBM Regressor**  
    - R¬≤ = 93.68% | MAE = 4.04 ng√†y | RMSE = 5.07 ng√†y
    
    ### Features (12 bi·∫øn)
    - **S·ªë**: severity_index, casualties, economic_loss_usd, response_time_hours, aid_amount_usd, response_efficiency_score, latitude, longitude
    - **Th·ªùi gian**: year, month
    - **Ph√¢n lo·∫°i**: country, disaster_type
    
    ### ƒê·∫∑c t√≠nh
    ‚úÖ Deterministic - Random State = 42
    ‚úÖ D·ª± ƒëo√°n nh·∫•t qu√°n - C√πng input = C√πng output
    ‚úÖ Train/Test Split: 80/20
    """)

# ============ TRANG D·ª∞ ƒêO√ÅN ============
def page_prediction(df):
    st.markdown('<div class="header">üéØ D·ª± ƒêo√°n H·ªìi Ph·ª•c</div>', unsafe_allow_html=True)
    
    xgb_m, _, _, _ = st.session_state.xgb
    lgb_m, _, _, _ = st.session_state.lgb
    
    if not xgb_m or not lgb_m:
        st.error("‚ùå Models kh√¥ng load ƒë∆∞·ª£c!")
        return
    
    st.markdown('<div class="success">‚úÖ XGBoost & LightGBM s·∫µn s√†ng</div>', unsafe_allow_html=True)
    
    c1, c2 = st.columns(2)
    
    with c1:
        country = st.selectbox("Qu·ªëc gia:", sorted(df['country'].unique()))
        disaster = st.selectbox("Lo·∫°i th·∫£m h·ªça:", sorted(df['disaster_type'].unique()))
        severity = st.slider("M·ª©c ƒë·ªô (1-10):", 1, 10, 5)
        casualties = st.number_input("Ng∆∞·ªùi th∆∞∆°ng vong:", 0, 100000, 100)
        loss = st.number_input("Thi·ªát h·∫°i (USD):", 0, 100000000, 1000000)
    
    with c2:
        resp_time = st.slider("Th·ªùi gian ph·∫£n ·ª©ng (gi·ªù):", 0, 48, 12)
        aid = st.number_input("H·ªó tr·ª£ (USD):", 0, 10000000, 500000)
        eff = st.slider("Hi·ªáu qu·∫£ (0-100):", 0, 100, 70)
        year = st.number_input("NƒÉm:", int(df['year'].min()), int(df['year'].max()), 2024)
        month = st.slider("Th√°ng:", 1, 12, 6)
        lat = st.number_input("Latitude:", -90.0, 90.0, 0.0)
        lon = st.number_input("Longitude:", -180.0, 180.0, 0.0)
    
    if st.button("üîÆ D·ª± ƒêo√°n!", use_container_width=True, type="primary"):
        inp = {
            'severity_index': severity,
            'casualties': casualties,
            'economic_loss_usd': loss,
            'response_time_hours': resp_time,
            'aid_amount_usd': aid,
            'response_efficiency_score': eff,
            'year': year,
            'month': month,
            'latitude': lat,
            'longitude': lon
        }
        
        try:
            pred_xgb = predict_xgb(country, disaster, inp)
            pred_lgb = predict_lgb(country, disaster, inp)
            
            st.divider()
            
            c1, c2, c3 = st.columns(3)
            
            with c1:
                st.markdown(f"""
                <div style='text-align: center; background: #ffe6e6; padding: 20px; border-radius: 8px;'>
                    <h4>üî∑ XGBoost</h4>
                    <h2 style='color: #d9534f;'>{pred_xgb:.1f}</h2>
                    <p>ng√†y</p>
                </div>
                """, unsafe_allow_html=True)
            
            with c2:
                st.markdown(f"""
                <div style='text-align: center; background: #e6f3ff; padding: 20px; border-radius: 8px;'>
                    <h4>üîπ LightGBM</h4>
                    <h2 style='color: #5cb85c;'>{pred_lgb:.1f}</h2>
                    <p>ng√†y</p>
                </div>
                """, unsafe_allow_html=True)
            
            with c3:
                avg = (pred_xgb + pred_lgb) / 2
                st.markdown(f"""
                <div style='text-align: center; background: #f0f8ff; padding: 20px; border-radius: 8px; border: 2px solid #1f77b4;'>
                    <h4>üìä Trung b√¨nh</h4>
                    <h2 style='color: #1f77b4;'>{avg:.1f}</h2>
                    <p>ng√†y</p>
                </div>
                """, unsafe_allow_html=True)
            
            st.info(f"‚ú® Hai model cho k·∫øt qu·∫£ g·∫ßn nhau (ch√™nh {abs(pred_xgb - pred_lgb):.2f} ng√†y) ‚Üí tin c·∫≠y cao!")
        except Exception as e:
            st.error(f"‚ùå L·ªói: {e}")

# ============ TRANG SO S√ÅNH ============
def page_comparison(df):
    st.markdown('<div class="header">‚öñÔ∏è So S√°nh 2 Models</div>', unsafe_allow_html=True)
    
    xgb_m, xgb_s, xgb_e, xgb_c = st.session_state.xgb
    lgb_m, lgb_s, lgb_e, lgb_c = st.session_state.lgb
    
    if not xgb_m or not lgb_m:
        st.error("‚ùå Models kh√¥ng s·∫µn s√†ng!")
        return
    
    n = st.slider("S·ªë b·∫£n ghi:", 10, min(500, len(df)), 100)
    
    if st.button("‚öñÔ∏è Ch·∫°y so s√°nh", use_container_width=True, type="primary"):
        try:
            s_df = df.sample(n=n, random_state=42).reset_index(drop=True)
            
            # XGBoost predictions
            x_list = []
            for _, r in s_df.iterrows():
                d = {
                    'severity_index': r['severity_index'],
                    'casualties': r['casualties'],
                    'economic_loss_usd': r['economic_loss_usd'],
                    'response_time_hours': r['response_time_hours'],
                    'aid_amount_usd': r['aid_amount_usd'],
                    'response_efficiency_score': r['response_efficiency_score'],
                    'year': r['year'],
                    'month': r['month'],
                    'latitude': r['latitude'],
                    'longitude': r['longitude'],
                    'country_encoded': xgb_e['country'].transform([r['country']])[0],
                    'disaster_type_encoded': xgb_e['disaster_type'].transform([r['disaster_type']])[0]
                }
                x_list.append([d.get(f, 0) for f in xgb_c['features']])
            
            X_xgb = pd.DataFrame(x_list, columns=xgb_c['features'])
            X_xgb_s = xgb_s.transform(X_xgb)
            p_xgb = xgb_m.predict(X_xgb_s)
            
            # LightGBM predictions
            l_list = []
            for _, r in s_df.iterrows():
                d = {
                    'severity_index': r['severity_index'],
                    'casualties': r['casualties'],
                    'economic_loss_usd': r['economic_loss_usd'],
                    'response_time_hours': r['response_time_hours'],
                    'aid_amount_usd': r['aid_amount_usd'],
                    'response_efficiency_score': r['response_efficiency_score'],
                    'year': r['year'],
                    'month': r['month'],
                    'latitude': r['latitude'],
                    'longitude': r['longitude'],
                    'country_encoded': lgb_e['country'].transform([r['country']])[0],
                    'disaster_type_encoded': lgb_e['disaster_type'].transform([r['disaster_type']])[0]
                }
                l_list.append([d.get(f, 0) for f in lgb_c['features']])
            
            X_lgb = pd.DataFrame(l_list, columns=lgb_c['features'])
            X_lgb_s = lgb_s.transform(X_lgb)
            p_lgb = lgb_m.predict(X_lgb_s)
            
            # B·∫£ng so s√°nh
            cmp_df = pd.DataFrame({
                'Qu·ªëc Gia': s_df['country'].values,
                'Th·∫£m H·ªça': s_df['disaster_type'].values,
                'Th·ª±c T·∫ø': s_df['recovery_days'].round(1).values,
                'XGBoost': p_xgb.round(1),
                'LightGBM': p_lgb.round(1),
                'Ch√™nh XGB': (s_df['recovery_days'].values - p_xgb).round(1),
                'Ch√™nh LGB': (s_df['recovery_days'].values - p_lgb).round(1)
            })
            
            st.subheader("üìä K·∫øt Qu·∫£ So S√°nh")
            st.dataframe(cmp_df, use_container_width=True, hide_index=True)
            
            st.divider()
            
            # Metrics
            mae_xgb = np.abs(s_df['recovery_days'].values - p_xgb).mean()
            mae_lgb = np.abs(s_df['recovery_days'].values - p_lgb).mean()
            rmse_xgb = np.sqrt(((s_df['recovery_days'].values - p_xgb) ** 2).mean())
            rmse_lgb = np.sqrt(((s_df['recovery_days'].values - p_lgb) ** 2).mean())
            r2_xgb = r2_score(s_df['recovery_days'], p_xgb)
            r2_lgb = r2_score(s_df['recovery_days'], p_lgb)
            
            c1, c2, c3 = st.columns(3)
            c1.metric("XGBoost R¬≤", f"{r2_xgb:.4f}", delta=f"{r2_xgb*100:.1f}%")
            c2.metric("LightGBM R¬≤", f"{r2_lgb:.4f}", delta=f"{r2_lgb*100:.1f}%")
            c3.metric("MAE Avg", f"{(mae_xgb + mae_lgb)/2:.2f}")
            
            st.divider()
            
            # Visualizations
            c1, c2 = st.columns(2)
            
            with c1:
                fig = px.scatter(x=s_df['recovery_days'], y=p_xgb, 
                               labels={'x': 'Th·ª±c T·∫ø', 'y': 'D·ª± ƒêo√°n XGBoost'},
                               title='XGBoost: Th·ª±c vs D·ª± ƒêo√°n',
                               trendline='ols')
                st.plotly_chart(fig, use_container_width=True)
            
            with c2:
                fig = px.scatter(x=s_df['recovery_days'], y=p_lgb,
                               labels={'x': 'Th·ª±c T·∫ø', 'y': 'D·ª± ƒêo√°n LightGBM'},
                               title='LightGBM: Th·ª±c vs D·ª± ƒêo√°n',
                               trendline='ols')
                st.plotly_chart(fig, use_container_width=True)
            
            # Error distribution
            c1, c2 = st.columns(2)
            
            with c1:
                fig = px.histogram(x=(s_df['recovery_days'].values - p_xgb),
                                 title='Ph√¢n ph·ªëi L·ªói XGBoost',
                                 nbins=20, color_discrete_sequence=['#d9534f'])
                st.plotly_chart(fig, use_container_width=True)
            
            with c2:
                fig = px.histogram(x=(s_df['recovery_days'].values - p_lgb),
                                 title='Ph√¢n ph·ªëi L·ªói LightGBM',
                                 nbins=20, color_discrete_sequence=['#5cb85c'])
                st.plotly_chart(fig, use_container_width=True)
        
        except Exception as e:
            st.error(f"‚ùå L·ªói: {e}")

# ============ TRANG BATCH ============
def page_batch(df):
    st.markdown('<div class="header">üì¶ D·ª± ƒêo√°n H√†ng Lo·∫°t</div>', unsafe_allow_html=True)
    
    xgb_m, _, _, _ = st.session_state.xgb
    lgb_m, _, _, _ = st.session_state.lgb
    
    if not xgb_m or not lgb_m:
        st.error("‚ùå Models kh√¥ng s·∫µn s√†ng!")
        return
    
    st.write("Upload file CSV c√≥ c√°c columns: country, disaster_type, severity_index, casualties, economic_loss_usd, response_time_hours, aid_amount_usd, response_efficiency_score, year, month, latitude, longitude")
    
    uploaded = st.file_uploader("Ch·ªçn file CSV:", type=['csv'])
    
    if uploaded and st.button("üìä D·ª± ƒëo√°n batch", use_container_width=True, type="primary"):
        try:
            batch_df = pd.read_csv(uploaded)
            results = []
            
            for _, row in batch_df.iterrows():
                inp = {
                    'severity_index': row['severity_index'],
                    'casualties': row['casualties'],
                    'economic_loss_usd': row['economic_loss_usd'],
                    'response_time_hours': row['response_time_hours'],
                    'aid_amount_usd': row['aid_amount_usd'],
                    'response_efficiency_score': row['response_efficiency_score'],
                    'year': row['year'],
                    'month': row['month'],
                    'latitude': row['latitude'],
                    'longitude': row['longitude']
                }
                
                p1 = predict_xgb(row['country'], row['disaster_type'], inp)
                p2 = predict_lgb(row['country'], row['disaster_type'], inp)
                
                results.append({
                    'Country': row['country'],
                    'Disaster': row['disaster_type'],
                    'XGBoost': p1,
                    'LightGBM': p2,
                    'Average': (p1 + p2) / 2
                })
            
            res_df = pd.DataFrame(results)
            st.dataframe(res_df, use_container_width=True, hide_index=True)
            
            # Download
            csv = res_df.to_csv(index=False)
            st.download_button(label="üì• T·∫£i k·∫øt qu·∫£",
                             data=csv,
                             file_name="predictions.csv",
                             mime="text/csv")
        
        except Exception as e:
            st.error(f"‚ùå L·ªói: {e}")

# ============ TRANG ABOUT ============
def page_about():
    st.markdown('<div class="header">‚ÑπÔ∏è V·ªÅ D·ª± √Ån</div>', unsafe_allow_html=True)
    
    st.markdown("""
    ### D·ª± ƒêo√°n H·ªìi Ph·ª•c Th·∫£m H·ªça
    
    **M·ª•c ti√™u**: X√¢y d·ª±ng 2 m√¥ h√¨nh ML ƒë·ªÉ d·ª± ƒëo√°n s·ªë ng√†y c·∫ßn thi·∫øt ƒë·ªÉ 
    ph·ª•c h·ªìi sau c√°c th·∫£m h·ªça thi√™n nhi√™n.
    
    **D·ªØ li·ªáu**: 50,000 b·∫£n ghi th·∫£m h·ªça (2018-2024) t·ª´ 20+ qu·ªëc gia
    
    **Models**:
    - XGBoost: R¬≤ = 93.64%, MAE = 4.05 ng√†y
    - LightGBM: R¬≤ = 93.68%, MAE = 4.04 ng√†y
    
    **T√≠nh nƒÉng**:
    - ‚úÖ D·ª± ƒëo√°n ƒë∆°n + batch
    - ‚úÖ So s√°nh hi·ªáu su·∫•t 2 models
    - ‚úÖ Visualizations & analytics
    - ‚úÖ Deterministic predictions (c√πng input = c√πng output)
    
    **T√°c gi·∫£**: Tr·∫ßn Minh Hi·∫øu
    """)

# ============ MAIN ============
def main():
    # Initialize session state
    if 'models_loaded' not in st.session_state:
        st.session_state.xgb = load_xgb()
        st.session_state.lgb = load_lgb()
        st.session_state.models_loaded = True
    
    # Load data
    df = load_data()
    if df is None:
        return
    
    # Header
    st.markdown('<div class="header">üåç D·ª± ƒêo√°n H·ªìi Ph·ª•c Th·∫£m H·ªça</div>', unsafe_allow_html=True)
    st.markdown('<div class="subheader">Dual Model: XGBoost & LightGBM</div>', unsafe_allow_html=True)
    
    # Navigation
    st.sidebar.title("üìç Menu")
    page = st.sidebar.radio("Ch·ªçn:", [
        "üìã T·ªïng Quan",
        "üîç Kh√°m Ph√°",
        "üìà Bi·ªÉu ƒê·ªì",
        "ü§ñ Models",
        "üéØ D·ª± ƒêo√°n",
        "‚öñÔ∏è So S√°nh",
        "üì¶ Batch",
        "‚ÑπÔ∏è About"
    ])
    
    if page == "üìã T·ªïng Quan":
        page_overview(df)
    elif page == "üîç Kh√°m Ph√°":
        page_explore(df)
    elif page == "üìà Bi·ªÉu ƒê·ªì":
        page_viz(df)
    elif page == "ü§ñ Models":
        page_model_info()
    elif page == "üéØ D·ª± ƒêo√°n":
        page_prediction(df)
    elif page == "‚öñÔ∏è So S√°nh":
        page_comparison(df)
    elif page == "üì¶ Batch":
        page_batch(df)
    elif page == "‚ÑπÔ∏è About":
        page_about()

if __name__ == "__main__":
    main()
